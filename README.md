# Language Detection - 22 langages
### Introduction

This repository contains the scripts and datasets used to train a supervised model. The model is trained on the task of language detection. The best model reaches an accuracy of 98% on 22 languages with a Multinomial Naive Bayes classification model and using bigrams. The Python file to train the model can be found in *naive-bayes/MultinomialNB-2/22-langues*.

The model is trained to recognize these languages :
* Arabic
* Chinese
* Dutch
* English
* Estonian
* French
* Hindi
* Indonesian
* Japanese
* Korean
* Latin
* Persian
* Portuguese
* Pushto
* Romanian
* Russian
* Spanish
* Swedish
* Tamil
* Thai
* Turkish
* Urdu

### The models

The scripts to train different models (with both unigrams and bigrams) on the task of language detection can be found in this repository. The models tested are : Naive Bayes (Multinomial, Gaussian), Linear Regression and K-Nearest-Neighbors.